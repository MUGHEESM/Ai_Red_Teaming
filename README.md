# AI Red Teamer

![AI Red Teaming](https://img.shields.io/badge/AI-Red%20Teamer-green)
![Status](https://img.shields.io/badge/Status-In%20Progress-yellow)
![Modules](https://img.shields.io/badge/Modules-12-blue)

## ğŸ“š Course Overview

This repository contains comprehensive study materials for the **AI Red Teamer Certification Path** - a hands-on certification path covering the full spectrum of AI security, from fundamental concepts to advanced attack and defense techniques.

**Certification Exam:** Expected April 2026

## ğŸ¯ Learning Path

The course is structured into **12 progressive modules**, each focusing on specific aspects of AI security:

### Module 01: Fundamentals of AI âœ… (Complete)
- **Duration:** 8 hours
- **Difficulty:** Medium
- **Status:** 100% Complete (25/25 topics)
- **Topics Covered:**
  - Introduction to Machine Learning
  - Mathematics Refresher for AI
  - Supervised Learning Algorithms
  - Linear Regression
  - Logistic Regression
  - Decision Trees
  - Naive Bayes
  - Support Vector Machines
  - Unsupervised Learning
  - K-Means Clustering
  - Principal Component Analysis
  - Anomaly Detection
  - Reinforcement Learning
  - Q-Learning & SARSA
  - Deep Learning Foundations
  - Neural Networks & CNNs
  - Recurrent Neural Networks
  - Generative AI & LLMs
  - Diffusion Models
  - Skills Assessment

### Module 02: Applications of AI in InfoSec âœ… (Complete)
- **Duration:** 8 hours
- **Difficulty:** Medium
- **Status:** 100% Complete (26/26 topics)
- **Topics Covered:**
  - Module Overview
  - Introduction
  - Environment Setup
  - JupyterLab
  - Python Libraries for AI
  - Datasets
  - Data Preprocessing
  - Data Transformation
  - Metrics for Evaluating a Model
  - Spam Classification
  - The Spam Dataset
  - Preprocessing the Spam Dataset
  - Feature Extraction
  - Training and Evaluation
  - Model Evaluation
  - Network Anomaly Detection
  - Preprocessing and Splitting the Dataset
  - Training and Evaluation
  - Model Evaluation
  - Malware Classification
  - The Malware Dataset
  - Preprocessing the Malware Dataset
  - The Model
  - Training and Evaluation
  - Model Evaluation
  - Skills Assessment

### Module 03: Introduction to Red Teaming AI ğŸŸ¡ (In Progress)
- **Topics:** 12
- **Status:** 25% Complete (3/12 topics)
- **Topics Covered:**
  - Module Overview
  - Introduction to Red Teaming ML-based Systems
  - Attacking ML-based Systems (ML OWASP Top 10)

### Module 04: Prompt Injection Attacks
- **Topics:** 13
- **Status:** Structure Created

### Module 05: LLM Output Attacks
- **Topics:** 15
- **Status:** Structure Created

### Module 06: AI Data Attacks
- **Topics:** 26
- **Status:** Structure Created

### Module 07: Attacking AI Applications and Systems
- **Topics:** 15
- **Status:** Structure Created

### Module 08: AI Evasion Foundations
- **Topics:** 13
- **Status:** Structure Created

### Module 09: AI Evasion First-Order Attacks
- **Topics:** 24
- **Status:** Structure Created

### Module 10: AI Evasion Sparsity Attacks
- **Topics:** 29
- **Status:** Structure Created

### Module 11: AI Privacy
- **Topics:** 22
- **Status:** Structure Created

### Module 12: AI Defense
- **Topics:** 22
- **Status:** Structure Created

## ğŸ“‚ Repository Structure

```
HTB_Ai_Red_Teaming/
â”œâ”€â”€ 01-Fundamentals-of-AI/           # Core AI/ML concepts
â”œâ”€â”€ 02-Applications-of-AI-in-InfoSec/
â”‚   â”œâ”€â”€ labs/                        # Jupyter notebooks for hands-on learning
â”‚   â”‚   â”œâ”€â”€ spam-detection/
â”‚   â”‚   â”œâ”€â”€ network-anomaly-detection/
â”‚   â”‚   â”œâ”€â”€ malware-classification/
â”‚   â”‚   â””â”€â”€ skills-assessment/
â”‚   â”œâ”€â”€ models/                      # Trained models
â”‚   â”œâ”€â”€ datasets/                    # Training/test datasets
â”‚   â””â”€â”€ images/                      # Flags and visualizations
â”œâ”€â”€ 03-Introduction-to-Red-Teaming-AI/
â”‚   â”œâ”€â”€ Research_Papers_reading/     # Academic papers (ML01-ML10)
â”‚   â””â”€â”€ images/                      # Attack diagrams and visualizations
â”œâ”€â”€ 04-Prompt-Injection-Attacks/
â”œâ”€â”€ 05-LLM-Output-Attacks/
â”œâ”€â”€ 06-AI-Data-Attacks/
â”œâ”€â”€ 07-Attacking-AI-Applications-and-Systems/
â”œâ”€â”€ 08-AI-Evasion-Foundations/
â”œâ”€â”€ 09-AI-Evasion-First-Order-Attacks/
â”œâ”€â”€ 10-AI-Evasion-Sparsity-Attacks/
â”œâ”€â”€ 11-AI-Privacy/
â”œâ”€â”€ 12-AI-Defense/
â”œâ”€â”€ labs/                            # Additional hands-on lab exercises
â”œâ”€â”€ datasets/                        # Shared datasets
â””â”€â”€ README.md
```

## ğŸ” Key Topics

### Offensive AI Security
- Prompt injection techniques
- LLM output manipulation
- Data poisoning attacks
- Model evasion techniques
- Privacy attacks on AI systems

### Defensive AI Security
- AI security best practices
- Defense mechanisms
- Model hardening
- Secure AI deployment

### Foundational Concepts
- Machine Learning fundamentals
- Deep Learning architectures
- Neural Networks
- Generative AI and LLMs

## ğŸ› ï¸ Prerequisites

Before starting this course, you should have:

- âœ… **Python Programming** (Required)
- ğŸ“Š **Basic Statistics** (Recommended)
- ğŸ”¢ **Linear Algebra** (Recommended)
- ğŸ“ **Calculus** (Recommended)

## ğŸ“– How to Use This Repository

1. **Sequential Learning:** Follow modules in order (01 â†’ 12) for best results
2. **Topic-Based:** Navigate directly to specific topics using the module folders
3. **Reference Material:** Use as a comprehensive reference for AI security concepts
4. **Practical Application:** Check `labs/` and `payloads/` for hands-on materials

## ğŸ“Š Progress Tracker

| Module | Topics | Completed | Status |
|--------|--------|-----------|--------|
| 01 - Fundamentals of AI | 25 | 25 | ğŸŸ¢ Complete |
| 02 - Applications in InfoSec | 26 | 26 | ğŸŸ¢ Complete |
| 03 - Red Teaming AI | 12 | 3 | ğŸŸ¡ In Progress |
| 04 - Prompt Injection | 13 | 0 | âšª Not Started |
| 05 - LLM Output Attacks | 15 | 0 | âšª Not Started |
| 06 - AI Data Attacks | 26 | 0 | âšª Not Started |
| 07 - Attacking AI Systems | 15 | 0 | âšª Not Started |
| 08 - AI Evasion Foundations | 13 | 0 | âšª Not Started |
| 09 - First-Order Attacks | 24 | 0 | âšª Not Started |
| 10 - Sparsity Attacks | 29 | 0 | âšª Not Started |
| 11 - AI Privacy | 22 | 0 | âšª Not Started |
| 12 - AI Defense | 22 | 0 | âšª Not Started |
| **Total** | **242** | **54** | **22%** |

## ğŸ“ Learning Objectives

By completing this course, you will:

- âœ… Understand fundamental AI/ML concepts and architectures
- âœ… Identify vulnerabilities in AI systems
- âœ… Execute various AI attack techniques
- âœ… Implement defensive measures for AI security
- âœ… Assess AI systems for security risks
- âœ… Apply red teaming methodologies to AI applications

## ğŸ”— Resources

- **HackTheBox Platform:** [https://www.hackthebox.eu](https://www.hackthebox.eu)
- **Course Materials:** This Repository
- **Community:** HTB Discord & Forums

## ğŸ“ Notes

- Each module contains detailed markdown files with comprehensive explanations
- Images and diagrams are included for visual learning
- Hands-on labs and practical exercises throughout the modules
- This is a hands-on AI Red Teamer certification path
- Skills assessments included to test practical knowledge
- Part of professional AI security certification program

## ğŸ¤ Contributing

This is a personal learning repository. If you find errors or have suggestions:
1. Open an issue
2. Submit a pull request
3. Contact the repository owner

## ğŸ“„ License

This repository contains educational materials for personal learning purposes.

## âš ï¸ Disclaimer

This course is for educational purposes only. Always obtain proper authorization before testing security techniques on systems you don't own. Unauthorized access to computer systems is illegal.

---

**Last Updated:** February 10, 2026  
**Repository Status:** Active Development  
**Current Focus:** Module 03 - Introduction to Red Teaming AI
